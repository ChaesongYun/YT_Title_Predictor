{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1WGKvCcXxtljwsQ81UC4oOfs8bNPX_YWW",
      "authorship_tag": "ABX9TyMinGmH4l65+bLVkN2/Pxxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaesongYun/YT_Title_Predictor/blob/main/Youtube_Title_Predictor_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YEcobUfSaSfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 Fine Tuning\n",
        "\n",
        "클리닝이 끝난 데이터를 BERT 자연어처리 인공지능 모델을 이용해서 fine tuning 작업을 해준다.<br>\n",
        "구글에서 pre-tranined된 BERT 모델을 받아준 뒤 데이터를 맞춤 제작을 한다.\n",
        "<br>\n",
        "맞춤제작이 끝나면 그 모델 유튜브 제목 퀄리티를 예측할 수 있다!(●'◡'●)\n",
        "\n",
        "1. Pre-tranined tokenizer 다운 받기\n",
        "2. Data sampling. 데이터 섞기\n",
        "3. 데이터셋을 training용과 validation용으로 나누기\n",
        "4. 인풋 데이터 만들기\n",
        "5. 학습모델 모델링\n",
        "6. 모델 compile\n",
        "7. 모델 fit\n",
        "8. 모델 평가하기\n",
        "9. 모델 다운로드"
      ],
      "metadata": {
        "id": "skR-_pGGitM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 가져오기\n",
        "!pip install transformers # Hugging Face에서 가져온다\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 선행된 Tokenizer 다운받기\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "I0Jwjk8OjkAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7FGKC3cj6xK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}